import pandas as pd
import numpy as np
from pathlib import Path

# --- Configuration pour MediaPipe ---
BASE_DIR = Path(__file__).resolve().parent.parent
FEATURES_FOLDER = BASE_DIR / 'data' / 'features'
OUTPUT_FOLDER = BASE_DIR / 'data' / 'preprocessed'
OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)

# Landmarks MediaPipe (33 points)
RIGHT_HIP_LM = 24  # Hanche droite
LEFT_HIP_LM = 23   # Hanche gauche
X_COL = f'lm_{RIGHT_HIP_LM}_x'
Y_COL = f'lm_{RIGHT_HIP_LM}_y'
Z_COL = f'lm_{RIGHT_HIP_LM}_z'
WINDOW_SIZE = 50

def normalize_and_segment(df_video, window_size=WINDOW_SIZE):
    """
    Normalise les coordonn√©es MediaPipe en tenant compte de la profondeur Z (distance cam√©ra).
    - Centrage sur la hanche droite
    - Normalisation par profondeur moyenne
    - Normalisation par distance entre hanches
    Cr√©e des s√©quences temporelles.
    """
    df_normalized = df_video.copy()
    
    # 1. Calcul de la profondeur moyenne (pour normaliser la distance √† la cam√©ra)
    z_cols = [f'lm_{i}_z' for i in range(33)]
    mean_z = df_normalized[z_cols].mean(axis=1)
    mean_z[mean_z == 0] = 1.0  # √âvite division par z√©ro
    
    # 2. Centrage sur la hanche droite
    center_x = df_normalized[X_COL].values
    center_y = df_normalized[Y_COL].values
    
    # 3. Normalisation XY en tenant compte de la profondeur Z
    # (compense la diff√©rence de taille due √† la distance √† la cam√©ra)
    for i in range(33):
        # Centrer
        df_normalized.loc[:, f'lm_{i}_x'] = df_normalized[f'lm_{i}_x'] - center_x
        df_normalized.loc[:, f'lm_{i}_y'] = df_normalized[f'lm_{i}_y'] - center_y
        
        # Normaliser par profondeur
        df_normalized.loc[:, f'lm_{i}_x'] = df_normalized[f'lm_{i}_x'] / mean_z
        df_normalized.loc[:, f'lm_{i}_y'] = df_normalized[f'lm_{i}_y'] / mean_z
    
    # 4. √âtape de Mise √† l'√âchelle (Scaling par distance hanches)
    # Calcule la distance entre les hanches (droite et gauche) comme facteur d'√©chelle suppl√©mentaire
    hip_distance = np.sqrt(
        (df_normalized[f'lm_{RIGHT_HIP_LM}_x'] - df_normalized[f'lm_{LEFT_HIP_LM}_x'])**2 +
        (df_normalized[f'lm_{RIGHT_HIP_LM}_y'] - df_normalized[f'lm_{LEFT_HIP_LM}_y'])**2
    )
    hip_distance[hip_distance == 0] = 1.0 
    
    # Normaliser par distance des hanches
    for i in range(33):
        df_normalized.loc[:, f'lm_{i}_x'] /= hip_distance
        df_normalized.loc[:, f'lm_{i}_y'] /= hip_distance
    
    # --- 5. Cr√©ation des S√©quences Temporelles ---
    # Utiliser X, Y normalis√©s + Z original (pour garder info profondeur)
    feature_cols = [col for col in df_normalized.columns if col.endswith('_x') or col.endswith('_y') or col.endswith('_z')]
    
    sequences = []
    
    for i in range(len(df_normalized) - window_size + 1):
        # Fen√™tre temporelle
        sequence = df_normalized.iloc[i : i + window_size][feature_cols].values
        sequences.append(sequence)
        
    return np.array(sequences) if sequences else None


def preprocess_all_videos(features_folder=FEATURES_FOLDER):
    """
    Pr√©traite tous les fichiers CSV d'extraction MediaPipe du dossier features.
    Normalise en tenant compte de la profondeur Z.
    """
    csv_files = sorted(features_folder.glob('*.csv'))
    
    if not csv_files:
        print(f"‚ùå Aucun fichier CSV trouv√© dans {features_folder}")
        return None
    
    print(f"üìÇ Traitement de {len(csv_files)} fichiers CSV...")
    print("=" * 70)
    
    all_sequences = []
    video_names = []
    
    for idx, csv_path in enumerate(csv_files, 1):
        try:
            print(f"[{idx:2d}/{len(csv_files)}] {csv_path.name:30s} ‚Üí ", end="", flush=True)
            
            # Charger le CSV
            df = pd.read_csv(csv_path)
            
            if len(df) < WINDOW_SIZE:
                print(f"‚ö†Ô∏è  {len(df)} frames < {WINDOW_SIZE}")
                continue
            
            # Pr√©traiter avec normalisation profondeur
            sequences = normalize_and_segment(df, WINDOW_SIZE)
            
            if sequences is not None:
                all_sequences.append(sequences)
                video_names.append(csv_path.stem)
                print(f"‚úì {sequences.shape[0]:4d} s√©quences")
            else:
                print("‚úó Pas de s√©quences")
                
        except Exception as e:
            print(f"‚ùå {str(e)[:50]}")
    
    if not all_sequences:
        print("‚ùå Aucune s√©quence valide g√©n√©r√©e!")
        return None
    
    # Concat√©ner tous les fichiers
    X_all = np.concatenate(all_sequences, axis=0)
    
    print("=" * 70)
    print(f"‚úÖ Pr√©traitement termin√©!")
    print(f"   Vid√©os trait√©es: {len(video_names)}/{len(csv_files)}")
    print(f"   Dimensions: ({X_all.shape[0]} s√©quences, {X_all.shape[1]} frames, {X_all.shape[2]} features)")
    
    # Sauvegarder les donn√©es
    output_path = OUTPUT_FOLDER / 'X_sequences.npy'
    np.save(output_path, X_all)
    print(f"\nüíæ Donn√©es: {output_path}")
    
    # Sauvegarder les noms de vid√©os
    video_names_path = OUTPUT_FOLDER / 'video_names.txt'
    with open(video_names_path, 'w') as f:
        for name in video_names:
            f.write(name + '\n')
    print(f"üíæ Noms: {video_names_path}")
    
    return X_all


if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("PR√âTRAITEMENT DES DONN√âES MEDIAPIPE")
    print("Normalisation avec profondeur Z (distance √† la cam√©ra)")
    print("=" * 70 + "\n")
    
    X_sequences = preprocess_all_videos()
    
    if X_sequences is not None:
        print("\n‚úÖ Pr√™t pour l'entra√Ænement du mod√®le!")